{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T21:16:12.481304Z",
     "start_time": "2024-10-04T21:16:12.478027Z"
    }
   },
   "cell_type": "code",
   "source": "import torch",
   "id": "76c7d0c2f5039822",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T21:16:12.689490Z",
     "start_time": "2024-10-04T21:16:12.687038Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_embeddings = torch.tensor([\n",
    "    [0.43, 0.15, 0.89], # Your    -> x_0\n",
    "    [0.55, 0.87, 0.66], # journey -> x_1\n",
    "    [0.57, 0.85, 0.64], # starts  -> x_2\n",
    "    [0.22, 0.58, 0.33], # with    -> x_3\n",
    "    [0.77, 0.25, 0.10], # one     -> x_4\n",
    "    [0.05, 0.80, 0.55], # step    -> x_5\n",
    "])"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# calculate context vectors naively",
   "id": "e3a33823200034cd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## calculate context vector for query 0",
   "id": "c2885be189f1e154"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T21:16:14.313877Z",
     "start_time": "2024-10-04T21:16:14.310276Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query_0 = input_embeddings[0]\n",
    "query_0"
   ],
   "id": "4184e2c560aec17f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4300, 0.1500, 0.8900])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T21:16:17.148230Z",
     "start_time": "2024-10-04T21:16:17.141905Z"
    }
   },
   "cell_type": "code",
   "source": [
    "attn_scores_0 = torch.empty(input_embeddings.shape[0])\n",
    "for i, x_i in enumerate(input_embeddings):\n",
    "    attn_scores_0[i] = torch.dot(x_i, query_0)\n",
    "attn_scores_0"
   ],
   "id": "868e6417bf91fb69",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T21:16:17.660896Z",
     "start_time": "2024-10-04T21:16:17.657544Z"
    }
   },
   "cell_type": "code",
   "source": [
    "attn_weights_0 = torch.softmax(attn_scores_0, dim=0)\n",
    "attn_weights_0"
   ],
   "id": "c6d7fe67e1aa8888",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2098, 0.2006, 0.1981, 0.1242, 0.1220, 0.1452])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T21:16:17.969971Z",
     "start_time": "2024-10-04T21:16:17.966390Z"
    }
   },
   "cell_type": "code",
   "source": [
    "context_vec_0 = torch.zeros(query_0.shape)\n",
    "for i, x_i in enumerate(input_embeddings):\n",
    "    context_vec_0 += attn_weights_0[i] * x_i\n",
    "context_vec_0"
   ],
   "id": "977c29f66aef3082",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4421, 0.5931, 0.5790])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## calculate context vector for query 1",
   "id": "29800ba29d11c062"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T21:16:18.343069Z",
     "start_time": "2024-10-04T21:16:18.338952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query_1 = input_embeddings[1]\n",
    "attn_scores_1 = torch.empty(input_embeddings.shape[0])\n",
    "for i, x_i in enumerate(input_embeddings):\n",
    "    attn_scores_1[i] = torch.dot(x_i, query_1)\n",
    "attn_weights_1 = torch.softmax(attn_scores_1, dim=0)\n",
    "context_vec_1 = torch.zeros(query_1.shape)\n",
    "for i, x_i in enumerate(input_embeddings):\n",
    "    context_vec_1 += attn_weights_1[i] * x_i\n",
    "context_vec_1"
   ],
   "id": "ff0d65b256c444c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4419, 0.6515, 0.5683])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## calculate context vector for query 2",
   "id": "1b590ce0b4d27e0f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T21:16:18.770082Z",
     "start_time": "2024-10-04T21:16:18.763720Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query_2 = input_embeddings[2]\n",
    "attn_scores_2 = torch.empty(input_embeddings.shape[0])\n",
    "for i, x_i in enumerate(input_embeddings):\n",
    "    attn_scores_2[i] = torch.dot(x_i, query_2)\n",
    "attn_weights_2 = torch.softmax(attn_scores_2, dim=0)\n",
    "context_vec_2 = torch.zeros(query_2.shape)\n",
    "for i, x_i in enumerate(input_embeddings):\n",
    "    context_vec_2 += attn_weights_2[i] * x_i\n",
    "context_vec_2"
   ],
   "id": "667b6e4aca65b3d9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4431, 0.6496, 0.5671])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## calculate context vector for query 3",
   "id": "feb4cad4c5f762e5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T21:16:19.173875Z",
     "start_time": "2024-10-04T21:16:19.167556Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query_3 = input_embeddings[3]\n",
    "attn_scores_3 = torch.zeros(input_embeddings.shape[0])\n",
    "for i, x_i in enumerate(input_embeddings):\n",
    "    attn_scores_3[i] = torch.dot(x_i, query_3)\n",
    "attn_weights_3 = torch.softmax(attn_scores_3, dim=0)\n",
    "context_vec_3 = torch.zeros(query_3.shape)\n",
    "for i, x_i in enumerate(input_embeddings):\n",
    "    context_vec_3 += attn_weights_3[i] * x_i\n",
    "context_vec_3"
   ],
   "id": "3cc5fb09be152094",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4304, 0.6298, 0.5510])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## calculate context vector for query 4",
   "id": "8bc802c5054457d9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T21:16:19.738960Z",
     "start_time": "2024-10-04T21:16:19.734858Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query_4 = input_embeddings[4]\n",
    "attn_scores_4 = torch.zeros(input_embeddings.shape[0])\n",
    "for i, x_i in enumerate(input_embeddings):\n",
    "    attn_scores_4[i] = torch.dot(x_i, query_4)\n",
    "attn_weights_4 = torch.softmax(attn_scores_4, dim=0)\n",
    "context_vec_4 = torch.zeros(query_4.shape)\n",
    "for i, x_i in enumerate(input_embeddings):\n",
    "    context_vec_4 += attn_weights_4[i] * x_i\n",
    "context_vec_4"
   ],
   "id": "c7efe424bea49535",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4671, 0.5910, 0.5266])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## calculate context vector for query 5",
   "id": "712b5675460e8570"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T21:16:20.404275Z",
     "start_time": "2024-10-04T21:16:20.398841Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query_5 = input_embeddings[5]\n",
    "attn_scores_5 = torch.zeros(input_embeddings.shape[0])\n",
    "for i, x_i in enumerate(input_embeddings):\n",
    "    attn_scores_5[i] = torch.dot(x_i, query_5)\n",
    "attn_weights_5 = torch.softmax(attn_scores_5, dim=0)\n",
    "context_vec_5 = torch.zeros(query_5.shape)\n",
    "for i, x_i in enumerate(input_embeddings):\n",
    "    context_vec_5 += attn_weights_5[i] * x_i\n",
    "context_vec_5"
   ],
   "id": "727125e9603fe054",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4177, 0.6503, 0.5645])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## combine context vectors",
   "id": "9dbd0d19a778ca57"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T21:21:30.153381Z",
     "start_time": "2024-10-04T21:21:30.150280Z"
    }
   },
   "cell_type": "code",
   "source": [
    "context_vecs = torch.stack([\n",
    "    context_vec_0,\n",
    "    context_vec_1,\n",
    "    context_vec_2,\n",
    "    context_vec_3,\n",
    "    context_vec_4,\n",
    "    context_vec_5,\n",
    "])\n",
    "context_vecs"
   ],
   "id": "fdf57965a7f7f636",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4421, 0.5931, 0.5790],\n",
       "        [0.4419, 0.6515, 0.5683],\n",
       "        [0.4431, 0.6496, 0.5671],\n",
       "        [0.4304, 0.6298, 0.5510],\n",
       "        [0.4671, 0.5910, 0.5266],\n",
       "        [0.4177, 0.6503, 0.5645]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# calculate context vectors in one go",
   "id": "c87cef9ce6a96ba0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T21:21:22.627618Z",
     "start_time": "2024-10-04T21:21:22.621560Z"
    }
   },
   "cell_type": "code",
   "source": [
    "attn_scores = input_embeddings @ input_embeddings.T\n",
    "attn_scores"
   ],
   "id": "df3d95e2b53abda",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9995, 0.9544, 0.9422, 0.4753, 0.4576, 0.6310],\n",
       "        [0.9544, 1.4950, 1.4754, 0.8434, 0.7070, 1.0865],\n",
       "        [0.9422, 1.4754, 1.4570, 0.8296, 0.7154, 1.0605],\n",
       "        [0.4753, 0.8434, 0.8296, 0.4937, 0.3474, 0.6565],\n",
       "        [0.4576, 0.7070, 0.7154, 0.3474, 0.6654, 0.2935],\n",
       "        [0.6310, 1.0865, 1.0605, 0.6565, 0.2935, 0.9450]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T21:21:23.585653Z",
     "start_time": "2024-10-04T21:21:23.579742Z"
    }
   },
   "cell_type": "code",
   "source": [
    "attn_weights = torch.softmax(attn_scores, dim=-1)\n",
    "attn_weights"
   ],
   "id": "a7d257a31b19ca1f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2098, 0.2006, 0.1981, 0.1242, 0.1220, 0.1452],\n",
       "        [0.1385, 0.2379, 0.2333, 0.1240, 0.1082, 0.1581],\n",
       "        [0.1390, 0.2369, 0.2326, 0.1242, 0.1108, 0.1565],\n",
       "        [0.1435, 0.2074, 0.2046, 0.1462, 0.1263, 0.1720],\n",
       "        [0.1526, 0.1958, 0.1975, 0.1367, 0.1879, 0.1295],\n",
       "        [0.1385, 0.2184, 0.2128, 0.1420, 0.0988, 0.1896]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T21:21:24.257532Z",
     "start_time": "2024-10-04T21:21:24.254076Z"
    }
   },
   "cell_type": "code",
   "source": [
    "context_vecs = attn_weights @ input_embeddings\n",
    "context_vecs"
   ],
   "id": "b89046b67ffad209",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4421, 0.5931, 0.5790],\n",
       "        [0.4419, 0.6515, 0.5683],\n",
       "        [0.4431, 0.6496, 0.5671],\n",
       "        [0.4304, 0.6298, 0.5510],\n",
       "        [0.4671, 0.5910, 0.5266],\n",
       "        [0.4177, 0.6503, 0.5645]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "11f80cb898e09add"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
